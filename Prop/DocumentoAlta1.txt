WIKIPEDIA
Algoritmo
Informatica.
En matem醫icas, l骻ica, ciencias de la computaci髇 y disciplinas relacionadas, un algoritmo (del griego y lat韓, dixit algorithmus y este a su vez del matem醫ico persa Al-Juarismi)1 es un conjunto prescrito de instrucciones o reglas bien definidas, ordenadas y finitas que permite llevar a cabo una actividad mediante pasos sucesivos que no generen dudas a quien deba hacer dicha actividad.2 Dados un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una soluci髇. Los algoritmos son el objeto de estudio de la algoritmia.
En la vida cotidiana, se emplean algoritmos frecuentemente para resolver problemas. Algunos ejemplos son los manuales de usuario, que muestran algoritmos para usar un aparato, o las instrucciones que recibe un trabajador por parte de su patr髇. Algunos ejemplos en matem醫ica son el algoritmo de multiplicaci髇, para calcular el producto, el algoritmo de la divisi髇 para calcular el cociente de dos n鷐eros, el algoritmo de Euclides para obtener el m醲imo com鷑 divisor de dos enteros positivos, o el m閠odo de Gauss para resolver un sistema de ecuaciones lineales.
En general, no existe ningun consenso definitivo en cuanto a la definici髇 formal de algoritmo. Muchos autores los se馻lan como listas de instrucciones para resolver un c醠culo o un problema abstracto, es decir, que un n鷐ero finito de pasos convierten los datos de un problema (entrada) en una soluci髇 (salida).1 2 3 4 5 6 Sin embargo cabe notar que algunos algoritmos no necesariamente tienen que terminar o resolver un problema en particular. Por ejemplo, una versi髇 modificada de la criba de Erat髎tenes que nunca termine de calcular n鷐eros primos no deja de ser un algoritmo.
A lo largo de la historia varios autores han tratado de definir formalmente a los algoritmos utilizando modelos matem醫icos. Esto fue realizado por Alonzo Church en 1936 con el concepto de "calculabilidad efectiva" basada en su c醠culo lambda y por Alan Turing bas醤dose en la m醧uina de Turing. Los dos enfoques son equivalentes, en el sentido en que se pueden resolver exactamente los mismos problemas con ambos enfoques.8 9 Sin embargo, estos modelos est醤 sujetos a un tipo particular de datos como son n鷐eros, s韒bolos o gr醘icas mientras que, en general, los algoritmos funcionan sobre una vasta cantidad de estructuras de datos.3 1 En general, la parte com鷑 en todas las definiciones se puede resumir en las siguientes tres propiedades siempre y cuando no consideremos algoritmos paralelos.
Tiempo secuencial. Un algoritmo funciona en tiempo discretizado 杙aso a paso�, definiendo as� una secuencia de estados computacionales por cada entrada v醠ida (la entrada son los datos que se le suministran al algoritmo antes de comenzar).
Estado abstracto. Cada estado computacional puede ser descrito formalmente utilizando una estructura de primer orden y cada algoritmo es independiente de su implementaci髇 (los algoritmos son objetos abstractos) de manera que en un algoritmo las estructuras de primer orden son invariantes bajo isomorfismo.
Exploraci髇 acotada. La transici髇 de un estado al siguiente queda completamente determinada por una descripci髇 fija y finita; es decir, entre cada estado y el siguiente solamente se puede tomar en cuenta una cantidad fija y limitada de t閞minos del estado actual.
En resumen, un algoritmo es muerete cualquier cosa que funcione paso a paso, donde cada paso se pueda describir sin ambig黣dad y sin hacer referencia a una computadora en particular, y adem醩 tiene un l韒ite fijo en cuanto a la cantidad de datos que se pueden leer/escribir en un solo paso. Esta amplia definici髇 abarca tanto a algoritmos pr醕ticos como aquellos que solo funcionan en teor韆, por ejemplo el m閠odo de Newton y la eliminaci髇 de Gauss-Jordan funcionan, al menos en principio, con n鷐eros de precisi髇 infinita; sin embargo no es posible programar la precisi髇 infinita en una computadora, y no por ello dejan de ser algoritmos.10 En particular es posible considerar una cuarta propiedad que puede ser usada para validar la tesis de Church-Turing de que toda funci髇 calculable se puede programar en una m醧uina de Turing (o equivalentemente, en un lenguaje de programaci髇 suficientemente general).
Aritmetizabilidad. Solamente operaciones innegablemente calculables est醤 disponibles en el paso inicial.
Un algoritmo se puede concebir como una funci髇 que transforma los datos de un problema (entrada) en los datos de una soluci髇 (salida). M醩 a鷑, los datos se pueden representar a su vez como secuencias de bits, y en general, de s韒bolos cualesquiera.1 9 11 Como cada secuencia de bits representa a un n鷐ero natural (v閍se Sistema binario), entonces los algoritmos son en esencia funciones de los n鷐eros naturales en los n鷐eros naturales que s� se pueden calcular. Es decir que todo algoritmo calcula una funci髇 {\displaystyle f:\mathbf {N} \to \mathbf {N} } {\displaystyle f:\mathbf {N} \to \mathbf {N} } donde cada n鷐ero natural es la codificaci髇 de un problema o de una soluci髇.
En ocasiones los algoritmos son susceptibles de nunca terminar, por ejemplo, cuando entran a un bucle infinito. Cuando esto ocurre, el algoritmo nunca devuelve ning鷑 valor de salida, y podemos decir que la funci髇 queda indefinida para ese valor de entrada. Por esta raz髇 se considera que los algoritmos son funciones parciales, es decir, no necesariamente definidas en todo su dominio de definici髇.
Cuando una funci髇 puede ser calculada por medios algor韙micos, sin importar la cantidad de memoria que ocupe o el tiempo que se tarde, se dice que dicha funci髇 es computable. No todas las funciones entre secuencias datos son computables. El problema de la parada es un ejemplo.
An醠isis de algoritmos mar desierto.